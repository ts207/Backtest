# Traceability Matrix

| Requirement | Status (Met / Partial / Missing) | Evidence (file:path + line numbers) | Risk Level (Tier 1 / 2 / 3) | Explanation | Proposed Fix | Verification Method |
|---|---|---|---|---|---|---|
| R1 Net-of-cost performance accounting | Met | `project/pipelines/backtest/backtest_strategies.py:379-410, 577-583`; orchestration usage `project/pipelines/run_all.py:540-543` | Tier 1 | Cost decomposition (gross/fees/slippage/impact/net) is implemented and emitted in `metrics.json`; run orchestrator forwards cost args. | Keep current behavior; add regression test on payload schema to prevent drift. | Static check of metrics payload fields and run_all passthrough. |
| R2 Time-respecting out-of-sample validation | Partial | Event-leak checks `project/pipelines/research/validate_expectancy_traps.py:203-216, 554-559`; no explicit walk-forward train/val/test schema found in research/backtest modules | Tier 1 | Leakage diagnostics exist, but no explicit walk-forward split framework with OOS reporting labels. | Add walk-forward split generator + split-tagged metrics in expectancy/backtest outputs. | Confirm split columns/artifacts (`split=train/val/test`) and OOS-only promotion gate. |
| R3 Multiple-testing / data-snooping controls | Missing | Candidate counts only: `project/pipelines/research/phase2_conditional_hypotheses.py:1032-1037`; no adjusted significance gate found | Tier 1 | Test counts are tracked, but no correction (adjusted p-values/DSR/PBO/reality-check style) appears in promotion logic. | Add multiplicity-adjusted metric and gate promotion on adjusted threshold. | Verify new adjusted metric fields + gate logic in phase2 output and tests. |
| R4 Data QA and provenance gating | Partial | QA checks `project/pipelines/clean/build_cleaned_15m.py:199-225, 254-280`; manifests `project/pipelines/_lib/run_manifest.py:22-40, 43-58`; usage via stage orchestration `project/pipelines/run_all.py:320-353` | Tier 1 | Strong timestamp/schema/gap checks and manifests exist; full source provenance/version ledger per dataset is incomplete. | Add explicit source/vendor/schema version IDs to run artifacts. | Inspect run manifests for provenance fields and failing behavior when missing. |
| R5 Mechanism-grounded feature coverage | Partial | Funding feature integration `project/pipelines/features/build_features_v1.py:115-140`; conditional funding buckets `project/pipelines/research/analyze_conditional_expectancy.py:212-251`; on-chain signal pipeline exists `project/pipelines/alpha_bundle/build_onchain_flow_signal.py` (module presence) | Tier 2 | Funding-centric coverage exists; broad OI/liquidation/revision-lag handling is not uniformly integrated in core feature pipeline. | Extend features schema for OI/liquidation + revision-lag metadata and usage in strategy inputs. | Verify feature columns + downstream consumption in strategy/backtest tests. |
| R6 Derivatives realism: funding + borrow in PnL | Missing | PnL model only turnover cost: `project/engine/pnl.py:13-21`; backtest cost decomposition lacks funding/borrow keys `project/pipelines/backtest/backtest_strategies.py:404-409` | Tier 1 | Carry strategy can be signaled, but realized PnL does not include funding transfer or borrow financing terms. | Add funding and borrow components to engine PnL and metrics decomposition. | Verify metrics include `funding_pnl` and `borrow_cost` with non-null values when data present. |
| R7 Reproducibility + versioning | Partial | Repro metadata emitted: `project/pipelines/backtest/backtest_strategies.py:350-376, 583-589`; seeds in phase2 eval `project/pipelines/research/phase2_conditional_hypotheses.py:983-985` | Tier 3 | Config digest/code revision/data snapshot IDs are present, but deterministic policy is not end-to-end and research diary fields are limited. | Enforce repository-wide seed contract and persist hypothesis diary (attempt IDs/test counts by stage). | Compare repeated runs with same seed/config; verify identical metrics hashes. |
| R8 Robustness suite (regime/cost/stability/capacity) | Partial | Regime/tail/symmetry/leakage suite `project/pipelines/research/validate_expectancy_traps.py:554-560`; fee stress `project/pipelines/backtest/backtest_strategies.py:607-649` | Tier 2 | Regime and cost stress exist; parameter-stability and capacity estimation are not evident. | Add parameter perturbation grid and capacity model (participation/depth constraints). | Validate new robustness artifacts include stability and capacity sections. |
| R9 Deployment gates + monitoring/kill-switch | Partial | Checklist gate output `project/pipelines/research/generate_recommendations_checklist.py:132-153, 215-223`; stage included in orchestration `project/pipelines/run_all.py:471-478`; non-fatal behavior tested `tests/test_run_all_phase2.py:34-45` | Tier 3 | Promotion checklist exists but lacks runtime monitoring primitives (feed/fill/cost/risk drift) and strict blocking in orchestration. | Introduce monitor metrics + hard fail gate for deployment phases. | Verify run_all blocks deployment stage when checklist/monitors fail. |
| R10 Case-study strategy coverage | Partial | Registry includes carry/spread templates `project/strategies/registry.py:13-19`; adapter tests `tests/test_strategy_adapters.py:42-53, 106-122`; candidate routing `project/pipelines/research/build_strategy_candidates.py:22-59` | Tier 2 | Carry/spread/mean-reversion templates exist; explicit MEV-aware risk filter and order-book microstructure execution template are not evident. | Add MEV risk-filter overlay and microstructure template with tests. | Verify new strategy/overlay IDs in registry and adapter tests. |
| R11 Survivorship-bias controls | Missing | Symbol universe is user-specified static list `project/pipelines/run_all.py:449`; no universe-history/delisting model found in inspected modules | Tier 1 | No auditable historical eligibility universe was found, so survivorship risk remains. | Implement time-varying universe snapshots and backtest eligibility joins. | Verify report artifact includes per-period universe membership and delisting handling. |

## Compliance Score

- Total requirements: **11**
- Met: **1**
- Partial: **7**
- Missing: **3**
- Compliance score: **(1 + 0.5Ã—7) / 11 = 0.4091**

## Risk Classification Summary

- Backtest validity risk: **HIGH** (Tier 1 gaps in R2, R3, R6, R11)
- Execution realism level: **MEDIUM-LOW** (cost/slippage modeled; funding/borrow and microstructure realism incomplete)
- Data integrity level: **MEDIUM** (strong timestamp/schema checks; provenance/version completeness partial)
